#!/usr/bin/env python3
"""
é›ªçƒä¸ªè‚¡è®¨è®ºæŠ“å– - APIæ–¹å¼
ç­–ç•¥ï¼š
1. ä¼˜å…ˆä½¿ç”¨ stock.xueqiu.com / statuses/search.json æ¥å£
2. è‡ªåŠ¨å¤„ç† Cookie å’Œ User-Agent
3. è¾“å‡º JSON åŸå§‹æ•°æ® + åˆ†æç»“æœ
"""

import requests
import json
from datetime import datetime
from typing import List, Dict, Any
import config

# å¤‡ç”¨ User-Agent åˆ—è¡¨
USER_AGENTS = [
    "Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.0 Mobile/15E148 Safari/604.1",
    "Mozilla/5.0 (iPad; CPU OS 16_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.0 Mobile/15E148 Safari/604.1",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
]

# å¤‡ç”¨ Cookie æ± ï¼ˆç¤ºä¾‹ï¼Œå®é™…åº”ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
COOKIE_POOL = [
    {"xq_a_token": config.COOKIES["xq_a_token"], "u": config.COOKIES["u"]},
]


def fetch_discussions(symbol: str, max_retries: int = 3) -> List[Dict[str, Any]]:
    """
    æŠ“å–é›ªçƒä¸ªè‚¡è®¨è®º
    ç­–ç•¥ï¼š
    1. ä¼˜å…ˆä½¿ç”¨ stock.xueqiu.com / statuses/search.json æ¥å£
    2. è‡ªåŠ¨å¤„ç† Cookie å’Œ User-Agent
    3. è¾“å‡º JSON åŸå§‹æ•°æ® + åˆ†æç»“æœ
    """
    # å°è¯•å¤šä¸ª API ç«¯ç‚¹
    api_endpoints = [
        f"https://stock.xueqiu.com/v5/statuses/search.json?symbol={symbol}&count=50&source=å…¨éƒ¨",
        f"https://xueqiu.com/query/v1/symbol/search/status?symbol={symbol}&size=50&source=ALL",
    ]
    
    headers_list = [
        {
            'User-Agent': USER_AGENTS[0],
            'Accept': 'application/json',
            'Accept-Language': 'zh-CN,zh;q=0.9',
            'Referer': 'https://xueqiu.com/',
            'Cookie': f'xq_a_token={config.COOKIES["xq_a_token"]}; u={config.COOKIES["u"]}'
        },
        {
            'User-Agent': USER_AGENTS[2],
            'Accept': 'application/json',
            'Accept-Language': 'en-US,en;q=0.9',
            'Referer': 'https://stock.xueqiu.com/',
            'Cookie': f'xq_a_token={config.COOKIES["xq_a_token"]}; u={config.COOKIES["u"]}'
        },
    ]
    
    for retry_count in range(max_retries):
        for endpoint_idx, url in enumerate(api_endpoints):
            headers = headers_list[endpoint_idx % len(headers_list)]
            
            print(f"   å°è¯• {retry_count + 1}/{max_retries}: {url[:60]}...")
            
            try:
                response = requests.get(url, headers=headers, timeout=30)
                print(f"   çŠ¶æ€ç : {response.status_code}")
                
                if response.status_code == 200:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ JSON å“åº”
                    content_type = response.headers.get('content-type', '')
                    
                    if 'application/json' in content_type:
                        try:
                            data = response.json()
                            
                            # ä¿å­˜åŸå§‹ JSON æ•°æ®
                            raw_file = f"/tmp/xueqiu_raw_{symbol}.json"
                            with open(raw_file, 'w', encoding='utf-8') as f:
                                json.dump(data, f, ensure_ascii=False, indent=2)
                            print(f"   ğŸ’¾ åŸå§‹JSONå·²ä¿å­˜: {raw_file}")
                            
                            # æå–è®¨è®ºåˆ—è¡¨
                            posts = data.get('list', []) or data.get('statuses', [])
                            
                            if posts:
                                print(f"   âœ“ è·å– {len(posts)} æ¡è®¨è®º")
                                return normalize_posts(posts, symbol)
                            else:
                                print(f"   âš ï¸ å“åº”ä¸­æ— è®¨è®ºæ•°æ®")
                                continue
                                
                        except requests.exceptions.JSONDecodeError as e:
                            print(f"   âš ï¸ JSONè§£æå¤±è´¥: {e}")
                            continue
                            
                    else:
                        # è¿”å› HTMLï¼Œå¯èƒ½æ˜¯ WAF æ‹¦æˆª
                        print(f"   âš ï¸ æ”¶åˆ°éJSONå“åº” ({content_type})ï¼Œå¯èƒ½æ˜¯WAFæ‹¦æˆª")
                        
                        # ä¿å­˜åŸå§‹å“åº”ç”¨äºåˆ†æ
                        raw_file = f"/tmp/xueqiu_waf_{symbol}_{endpoint_idx}.html"
                        with open(raw_file, 'w', encoding='utf-8') as f:
                            f.write(response.text)
                        print(f"   ğŸ’¾ WAFå“åº”å·²ä¿å­˜: {raw_file}")
                        continue
                        
                elif response.status_code == 404:
                    print(f"   âš ï¸ 404 ç«¯ç‚¹ä¸å¯ç”¨ï¼Œå°è¯•ä¸‹ä¸€ä¸ª...")
                    continue
                    
                elif response.status_code == 401:
                    print(f"   âš ï¸ è®¤è¯å¤±è´¥ (401)ï¼Œå°è¯•æ›´æ¢Cookie...")
                    # å°è¯•æ›´æ¢ Cookie
                    if endpoint_idx < len(COOKIE_POOL):
                        headers['Cookie'] = f'xq_a_token={COOKIE_POOL[endpoint_idx]["xq_a_token"]}; u={COOKIE_POOL[endpoint_idx]["u"]}'
                    continue
                    
                else:
                    print(f"   âš ï¸ HTTPé”™è¯¯: {response.status_code}")
                    continue
                    
            except Exception as e:
                print(f"   âš ï¸ è¯·æ±‚å¼‚å¸¸: {e}")
                continue
    
    print(f"   âŒ æ‰€æœ‰å°è¯•å‡å¤±è´¥")
    return []


def normalize_posts(posts: List[Dict], symbol: str) -> List[Dict[str, Any]]:
    """
    æ ‡å‡†åŒ–è®¨è®ºæ•°æ®
    æå–å…³é”®å­—æ®µç”¨äºåç»­åˆ†æ
    """
    normalized = []

    for post in posts:
        # æå–çº¯æ–‡æœ¬ï¼ˆå»é™¤HTMLæ ‡ç­¾ï¼‰
        html_text = post.get('text', '')
        plain_text = re.sub(r'<[^>]+>', '', html_text)
        plain_text = plain_text.replace('<br/>', '\n').strip()

        # æå–ç”¨æˆ·ä¿¡æ¯
        user = post.get('user', {})
        author = user.get('screen_name', 'åŒ¿åç”¨æˆ·')

        # æ—¶é—´æˆ³è½¬æ¢
        created_at = post.get('created_at', 0)
        time_str = format_time(created_at)

        # æµè§ˆé‡
        view_count = post.get('view_count', 0)

        normalized.append({
            "id": post.get('id', 0),
            "text": plain_text,
            "author": author,
            "author_followers": user.get('followers_count', 0),
            "time": time_str,
            "timestamp": created_at,
            "views": view_count,
            "likes": post.get('like_count', 0),
            "comments": post.get('reply_count', 0),
            "retweets": post.get('retweet_count', 0),
            "source": post.get('source', ''),
            "symbol": symbol,
        })

    return normalized


def format_time(timestamp: int) -> str:
    """å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºå¯è¯»æ ¼å¼"""
    if not timestamp:
        return "æœªçŸ¥æ—¶é—´"

    from datetime import datetime
    dt = datetime.fromtimestamp(timestamp / 1000)
    now = datetime.now()

    # è®¡ç®—æ—¶é—´å·®
    diff = now - dt

    if diff.days == 0:
        # åŒä¸€å¤©
        return dt.strftime("ä»Šå¤© %H:%M")
    elif diff.days == 1:
        return dt.strftime("æ˜¨å¤© %H:%M")
    elif diff.days < 7:
        return f"{diff.days}å¤©å‰"
    else:
        return dt.strftime("%m-%d %H:%M")


if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("ç”¨æ³•: python fetch_status.py <è‚¡ç¥¨ä»£ç >")
        print("ç¤ºä¾‹: python fetch_status.py SZ300456")
        sys.exit(1)

    symbol = sys.argv[1]
    print(f"ğŸ“¡ æ­£åœ¨è·å– {symbol} çš„è®¨è®º...")

    posts = fetch_discussions(symbol)

    print(f"\nâœ… æ€»å…±è·å– {len(posts)} æ¡è®¨è®º")

    # ä¿å­˜
    with open("/tmp/xueqiu_status_raw.json", "w", encoding="utf-8") as f:
        json.dump(posts, f, ensure_ascii=False, indent=2)

    print("ğŸ’¾ å·²ä¿å­˜åˆ° /tmp/xueqiu_status_raw.json")

    # æ˜¾ç¤ºå‰å‡ æ¡
    for i, post in enumerate(posts[:3], 1):
        print(f"\n{i}. [{post['author']}] {post['time']}")
        print(f"   {post['text'][:80]}...")
