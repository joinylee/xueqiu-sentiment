#!/usr/bin/env python3
"""
é›ªçƒèˆ†æƒ…ç›‘æ§ - V7 ç»ˆæç‰ˆ
ç”¨æ­£åˆ™ç›´æ¥æå–å…³é”®å­—æ®µï¼Œç»•è¿‡ JSON è§£æ
"""

import subprocess
import re
import time
import os
from datetime import datetime

SYMBOLS = [
    ("SH600118", "ä¸­å›½å«æ˜Ÿ"),
    ("SZ002155", "æ¹–å—é»„é‡‘"), 
    ("SZ300456", "èµ›å¾®ç”µå­"),
    ("SH600879", "èˆªå¤©ç”µå­"),
    ("SZ002565", "é¡ºçè‚¡ä»½"),
]

def get_sentiment(text):
    bullish = ['æ¶¨', 'åˆ©å¥½', 'çœ‹å¥½', 'ä¹°å…¥', 'çªç ´', 'å¼ºåŠ¿', 'æ–°é«˜', 'åšå¤š', 'æŠ„åº•']
    bearish = ['è·Œ', 'åˆ©ç©º', 'çœ‹ç©º', 'å–å‡º', 'ç ´ä½', 'å¼±åŠ¿', 'æ–°ä½', 'åšç©º', 'å‰²è‚‰', 'æ±ªæ±ª']
    text = text.lower()
    bull = sum(1 for w in bullish if w in text)
    bear = sum(1 for w in bearish if w in text)
    if bull > bear: return "ğŸŸ¢"
    elif bear > bull: return "ğŸ”´"
    return "âšª"

def clean_text(text):
    """æ¸…æ´—æ–‡æœ¬"""
    # åè½¬ä¹‰
    text = text.replace('\\n', '\n').replace('\\t', ' ').replace('\\"', '"')
    # å»é™¤ HTML
    text = re.sub(r'<[^>]+>', ' ', text)
    # å»é™¤è‚¡ç¥¨æ ‡è®°
    text = re.sub(r'\$[^$]+\$', '', text)
    # æ¸…ç†ç©ºæ ¼
    text = ' '.join(text.split())
    return text.strip()

def extract_posts(raw_text):
    """ç”¨æ­£åˆ™ä»åŸå§‹æ–‡æœ¬ä¸­æå–å¸–å­"""
    posts = []
    
    # æ¨¡å¼1: æå– "text":"å†…å®¹" å’Œ "created_at":æ—¶é—´æˆ³
    # æ‰¾åˆ° text å­—æ®µ
    text_matches = list(re.finditer(r'"text":"(.*?)"[,}]', raw_text, re.DOTALL))
    time_matches = list(re.finditer(r'"created_at":(\d+)', raw_text))
    author_matches = list(re.finditer(r'"screen_name":"(.*?)"', raw_text))
    
    print(f"   æ‰¾åˆ° {len(text_matches)} ä¸ªæ–‡æœ¬, {len(time_matches)} ä¸ªæ—¶é—´, {len(author_matches)} ä¸ªä½œè€…")
    
    for i, tm in enumerate(text_matches[:15]):  # åªå–å‰15æ¡
        try:
            text = tm.group(1)
            text = clean_text(text)
            
            if len(text) < 5 or len(text) > 500:
                continue
            
            # å¯¹åº”çš„æ—¶é—´
            ts = int(time_matches[i].group(1)) if i < len(time_matches) else 0
            # å¯¹åº”çš„ä½œè€…
            author = author_matches[i].group(1) if i < len(author_matches) else "åŒ¿å"
            author = author.replace('\\"', '"')
            
            posts.append({
                'text': text[:120],
                'author': author[:20],
                'time': datetime.fromtimestamp(ts/1000).strftime('%m-%d %H:%M') if ts else '',
                'sentiment': get_sentiment(text),
            })
        except Exception as e:
            continue
    
    return posts

def fetch_stock(symbol, name):
    """æŠ“å–å•åªè‚¡ç¥¨"""
    print(f"\nğŸ“ˆ {name} ({symbol})")
    
    ts = int(time.time() * 1000)
    url = f"https://xueqiu.com/statuses/search.json?count=20&symbol={symbol}&page=1&_={ts}"
    
    try:
        # æ‰“å¼€
        r1 = subprocess.run(['openclaw', 'browser', 'open', url], 
            capture_output=True, text=True, timeout=30)
        
        m = re.search(r'id:\s*([A-F0-9]+)', r1.stdout)
        if not m: 
            print("   âŒ æ— æ³•æ‰“å¼€")
            return []
        
        tid = m.group(1)
        time.sleep(2)
        
        # å¿«ç…§
        r2 = subprocess.run(['openclaw', 'browser', 'snapshot', '--target-id', tid],
            capture_output=True, text=True, timeout=30)
        
        # å…³é—­
        subprocess.run(['openclaw', 'browser', 'close', '--target-id', tid],
            capture_output=True, timeout=10)
        
        # æå–åŸå§‹ JSON
        line = r2.stdout.strip()
        
        # æ‰¾åˆ° JSON å¼€å§‹ä½ç½® - æ ¼å¼: "{\"about\":... æˆ– "{...
        # åœ¨ generic [ref=e2]: åé¢
        if 'generic [ref=' not in line:
            print("   âŒ ä¸æ˜¯ generic æ ¼å¼")
            return []
        
        # æ‰¾åˆ° : "{ çš„ä½ç½®
        marker = ': "'
        pos = line.find(marker)
        if pos < 0:
            print("   âŒ æ‰¾ä¸åˆ°æ•°æ®æ ‡è®°")
            return []
        
        start = pos + 2  # è·³è¿‡ : "
        
        # æ‰¾ç»“æŸä½ç½® - æœ€åä¸€ä¸ª "}
        end = line.rfind('"')
        if end <= start:
            print("   âŒ æ‰¾ä¸åˆ°ç»“æŸæ ‡è®°")
            return []
        
        if start < 0 or end <= start:
            print("   âŒ æ ¼å¼é”™è¯¯")
            return []
        
        raw = line[start+1:end+1]  # å»æ‰å¤–å±‚å¼•å·
        
        # åè½¬ä¹‰
        raw = raw.replace('\\"', '"').replace('\\\\', '\\')
        
        # æå–å¸–å­
        posts = extract_posts(raw)
        
        bull = len([p for p in posts if p['sentiment'] == 'ğŸŸ¢'])
        bear = len([p for p in posts if p['sentiment'] == 'ğŸ”´'])
        
        print(f"   âœ… {len(posts)} æ¡ (ğŸŸ¢{bull} ğŸ”´{bear})")
        
        for i, p in enumerate(posts[:3], 1):
            print(f"   {i}. {p['sentiment']} {p['text'][:40]}...")
        
        return posts
        
    except Exception as e:
        print(f"   âŒ é”™è¯¯: {str(e)[:40]}")
        return []

def main():
    print("=" * 60)
    print("ğŸ§ é›ªçƒèˆ†æƒ…ç›‘æ§ - V7 ç»ˆæç‰ˆ")
    print(f"â° {datetime.now().strftime('%H:%M:%S')}")
    print("=" * 60)
    
    all_data = {}
    total = 0
    
    for symbol, name in SYMBOLS:
        posts = fetch_stock(symbol, name)
        all_data[symbol] = posts
        total += len(posts)
        time.sleep(1)
    
    print("\n" + "=" * 60)
    print(f"ğŸ“Š æ€»è®¡: {total} æ¡")
    print("=" * 60)
    
    for symbol, name in SYMBOLS:
        print(f"   {name}: {len(all_data[symbol])} æ¡")

if __name__ == "__main__":
    main()
