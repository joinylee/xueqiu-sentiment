#!/usr/bin/env python3
"""
é›ªçƒèˆ†æƒ…ç›‘æ§ - V9 ç”Ÿäº§ç‰ˆ
å®Œæ•´åŠŸèƒ½ï¼šå¤šé¡µæŠ“å– + è‚¡ç¥¨æ±  + æŠ¥å‘Šç”Ÿæˆ
"""

import subprocess
import re
import time
import os
import json
from datetime import datetime

# ============ è‚¡ç¥¨æ± é…ç½® ============
SYMBOLS = [
    ("SH600118", "ä¸­å›½å«æ˜Ÿ"),
    ("SZ002155", "æ¹–å—é»„é‡‘"),
    ("SZ300456", "èµ›å¾®ç”µå­"),
    ("SH600879", "èˆªå¤©ç”µå­"),
    ("SZ002565", "é¡ºçè‚¡ä»½"),
    ("SH603667", "äº”æ´²æ–°æ˜¥"),
    ("SH601869", "é•¿é£å…‰çº¤"),
    ("SZ002112", "ä¸‰å˜ç§‘æŠ€"),
    ("SZ002361", "ç¥å‰‘è‚¡ä»½"),
    ("SZ002342", "å·¨åŠ›ç´¢å…·"),
    ("SZ300136", "ä¿¡ç»´é€šä¿¡"),
]

OUTPUT_DIR = "/Users/joinylee/Openclaw/xueqiu_sentiment/reports"
MAX_PAGES = 7  # æ¯å¤©æŠ“å–7é¡µ

# ============ æƒ…ç»ªåˆ†æ ============
def get_sentiment(text):
    bullish = ['æ¶¨', 'åˆ©å¥½', 'çœ‹å¥½', 'ä¹°å…¥', 'çªç ´', 'å¼ºåŠ¿', 'æ–°é«˜', 'åšå¤š', 'æŠ„åº•', 'æ‹‰å‡', 'æ¶¨åœ']
    bearish = ['è·Œ', 'åˆ©ç©º', 'çœ‹ç©º', 'å–å‡º', 'ç ´ä½', 'å¼±åŠ¿', 'æ–°ä½', 'åšç©º', 'å‰²è‚‰', 'æ±ªæ±ª', 'å‰²äº†', 'æ‰“å‹']
    text = text.lower()
    bull = sum(1 for w in bullish if w in text)
    bear = sum(1 for w in bearish if w in text)
    if bull > bear: return "ğŸŸ¢"
    elif bear > bull: return "ğŸ”´"
    return "âšª"

def clean_text(text):
    """æ¸…æ´—æ–‡æœ¬"""
    text = text.replace('\\n', '\n').replace('\\t', ' ').replace('\\"', '"')
    text = re.sub(r'<[^>]+>', ' ', text)
    text = re.sub(r'\$[^$]+\$', '', text)
    text = ' '.join(text.split())
    return text.strip()

def extract_posts(raw_text):
    """æå–å¸–å­"""
    posts = []
    text_matches = list(re.finditer(r'"text":"(.*?)"[,}]', raw_text, re.DOTALL))
    time_matches = list(re.finditer(r'"created_at":(\d+)', raw_text))
    author_matches = list(re.finditer(r'"screen_name":"(.*?)"', raw_text))
    
    for i, tm in enumerate(text_matches[:20]):
        try:
            text = tm.group(1)
            text = clean_text(text)
            if len(text) < 5 or len(text) > 600:
                continue
            
            ts = int(time_matches[i].group(1)) if i < len(time_matches) else 0
            author = author_matches[i].group(1) if i < len(author_matches) else "åŒ¿å"
            author = author.replace('\\"', '"')
            
            posts.append({
                'text': text[:200],
                'author': author[:20],
                'time': datetime.fromtimestamp(ts/1000).strftime('%m-%d %H:%M') if ts else '',
                'sentiment': get_sentiment(text),
                'timestamp': ts,
            })
        except:
            continue
    
    return posts

def fetch_page(symbol, page=1):
    """æŠ“å–å•é¡µ"""
    ts = int(time.time() * 1000)
    url = f"https://xueqiu.com/statuses/search.json?count=20&symbol={symbol}&page={page}&_={ts}"
    
    try:
        r1 = subprocess.run(['openclaw', 'browser', 'open', url], 
            capture_output=True, text=True, timeout=30)
        
        m = re.search(r'id:\s*([A-F0-9]+)', r1.stdout)
        if not m: return []
        
        tid = m.group(1)
        time.sleep(2)
        
        r2 = subprocess.run(['openclaw', 'browser', 'snapshot', '--target-id', tid],
            capture_output=True, text=True, timeout=30)
        
        subprocess.run(['openclaw', 'browser', 'close', '--target-id', tid],
            capture_output=True, timeout=10)
        
        line = r2.stdout.strip()
        if 'generic [ref=' not in line:
            return []
        
        pos = line.find(': "')
        if pos < 0: return []
        
        start = pos + 2
        end = line.rfind('"')
        if end <= start: return []
        
        raw = line[start:end]
        raw = raw.replace('\\"', '"').replace('\\\\', '\\')
        
        return extract_posts(raw)
        
    except Exception as e:
        return []

def fetch_stock(symbol, name):
    """æŠ“å–å¤šé¡µ"""
    print(f"\nğŸ“ˆ {name} ({symbol})")
    
    all_posts = []
    seen_texts = set()
    
    for page in range(1, MAX_PAGES + 1):
        print(f"   ç¬¬ {page}/{MAX_PAGES} é¡µ...", end=" ", flush=True)
        
        posts = fetch_page(symbol, page)
        if not posts:
            print("æ— æ•°æ®")
            break
        
        new_posts = []
        for p in posts:
            if p['text'] not in seen_texts:
                seen_texts.add(p['text'])
                new_posts.append(p)
        
        all_posts.extend(new_posts)
        print(f"{len(new_posts)} æ¡")
        time.sleep(1.5)
    
    bull = len([p for p in all_posts if p['sentiment'] == 'ğŸŸ¢'])
    bear = len([p for p in all_posts if p['sentiment'] == 'ğŸ”´'])
    
    print(f"   âœ… æ€»è®¡: {len(all_posts)} æ¡ (ğŸŸ¢{bull} ğŸ”´{bear})")
    
    # æ˜¾ç¤ºæœ€æ–°3æ¡
    for i, p in enumerate(sorted(all_posts, key=lambda x: x['timestamp'], reverse=True)[:3], 1):
        print(f"   {i}. {p['sentiment']} [{p['time']}] {p['text'][:45]}...")
    
    return all_posts

def generate_report(all_data):
    """ç”Ÿæˆ Markdown æŠ¥å‘Š"""
    now = datetime.now()
    report = f"""# ğŸ“Š é›ªçƒèˆ†æƒ…ç›‘æ§æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {now.strftime('%Y-%m-%d %H:%M:%S')}  
**ç›‘æ§è‚¡ç¥¨**: {len(SYMBOLS)} åª  
**æŠ“å–é¡µæ•°**: {MAX_PAGES} é¡µ/åª

---

"""
    
    total_bull = total_bear = 0
    
    for symbol, name in SYMBOLS:
        posts = all_data.get(symbol, [])
        bull = len([p for p in posts if p['sentiment'] == 'ğŸŸ¢'])
        bear = len([p for p in posts if p['sentiment'] == 'ğŸ”´'])
        total_bull += bull
        total_bear += bear
        
        report += f"""## ğŸ“ˆ {name} ({symbol})

**ç»Ÿè®¡**: å…± {len(posts)} æ¡ | ğŸŸ¢ {bull} | ğŸ”´ {bear} | âšª {len(posts) - bull - bear}

"""
        
        if posts:
            # æŒ‰æ—¶é—´æ’åºï¼Œå–æœ€æ–°5æ¡
            sorted_posts = sorted(posts, key=lambda x: x.get('timestamp', 0), reverse=True)
            report += "### æœ€æ–°è®¨è®º\n\n"
            for i, p in enumerate(sorted_posts[:5], 1):
                report += f"{i}. {p['sentiment']} **{p['time']}** | {p['author']}\n"
                report += f"   > {p['text'][:100]}{'...' if len(p['text']) > 100 else ''}\n\n"
        else:
            report += "*æš‚æ— æ•°æ®*\n\n"
        
        report += "---\n\n"
    
    # æ·»åŠ æ±‡æ€»
    total = sum(len(v) for v in all_data.values())
    report += f"""## ğŸ“Š æ±‡æ€»

**æ€»è®¡**: {total} æ¡è®¨è®º  
**åˆ©å¤š**: {total_bull} æ¡ ğŸŸ¢  
**åˆ©ç©º**: {total_bear} æ¡ ğŸ”´  
**ä¸­æ€§**: {total - total_bull - total_bear} æ¡ âšª

"""
    
    return report

def main():
    print("=" * 70)
    print("ğŸ§ é›ªçƒèˆ†æƒ…ç›‘æ§ - V9 ç”Ÿäº§ç‰ˆ")
    print(f"â° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“Š è‚¡ç¥¨æ•°: {len(SYMBOLS)} | é¡µæ•°: {MAX_PAGES}")
    print("=" * 70)
    
    all_data = {}
    total_count = 0
    
    for i, (symbol, name) in enumerate(SYMBOLS, 1):
        print(f"\n[{i}/{len(SYMBOLS)}]", end="")
        posts = fetch_stock(symbol, name)
        all_data[symbol] = posts
        total_count += len(posts)
        time.sleep(1)
    
    # ä¿å­˜ JSON
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    ts = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    json_file = os.path.join(OUTPUT_DIR, f'xueqiu_{ts}.json')
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump({
            'fetch_time': datetime.now().isoformat(),
            'max_pages': MAX_PAGES,
            'total_posts': total_count,
            'data': all_data
        }, f, ensure_ascii=False, indent=2)
    
    # ç”Ÿæˆå¹¶ä¿å­˜ Markdown æŠ¥å‘Š
    report = generate_report(all_data)
    md_file = os.path.join(OUTPUT_DIR, f'report_{ts}.md')
    with open(md_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    # æ‰“å°æ±‡æ€»
    print("\n" + "=" * 70)
    print("ğŸ“Š æ±‡æ€»æŠ¥å‘Š")
    print("=" * 70)
    print(f"æ€»è®¡æŠ“å–: {total_count} æ¡")
    print()
    
    for symbol, name in SYMBOLS:
        posts = all_data[symbol]
        bull = len([p for p in posts if p['sentiment'] == 'ğŸŸ¢'])
        bear = len([p for p in posts if p['sentiment'] == 'ğŸ”´'])
        print(f"  {name:10s} ({symbol}): {len(posts):3d} æ¡ (ğŸŸ¢{bull:2d} ğŸ”´{bear:2d})")
    
    print()
    print(f"ğŸ’¾ JSON: {json_file}")
    print(f"ğŸ“„ æŠ¥å‘Š: {md_file}")
    print("=" * 70)
    print("âœ… å®Œæˆ!")

if __name__ == "__main__":
    main()
