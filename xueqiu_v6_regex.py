#!/usr/bin/env python3
"""
é›ªçƒèˆ†æƒ…ç›‘æ§ - V6 æ­£åˆ™æå–ç‰ˆ
ä¸è§£æå®Œæ•´ JSONï¼Œç›´æ¥ç”¨æ­£åˆ™æå–å…³é”®å­—æ®µ
"""

import subprocess
import re
import time
import os
from datetime import datetime
from typing import List, Dict

SYMBOLS = [
    ("SH600118", "ä¸­å›½å«æ˜Ÿ"),
    ("SZ002155", "æ¹–å—é»„é‡‘"),
    ("SZ300456", "èµ›å¾®ç”µå­"),
    ("SH600879", "èˆªå¤©ç”µå­"),
    ("SZ002565", "é¡ºçè‚¡ä»½"),
]

OUTPUT_DIR = "/Users/joinylee/Openclaw/xueqiu_sentiment/reports"

def analyze_sentiment(text: str) -> str:
    bullish = ['æ¶¨', 'åˆ©å¥½', 'çœ‹å¥½', 'ä¹°å…¥', 'çªç ´', 'å¼ºåŠ¿', 'æ–°é«˜', 'åšå¤š', 'æŠ„åº•', 'æ‹‰å‡']
    bearish = ['è·Œ', 'åˆ©ç©º', 'çœ‹ç©º', 'å–å‡º', 'ç ´ä½', 'å¼±åŠ¿', 'æ–°ä½', 'åšç©º', 'å‰²è‚‰', 'æ±ªæ±ª', 'å‰²äº†', 'æ‰“å‹']
    text = text.lower()
    bull = sum(1 for w in bullish if w in text)
    bear = sum(1 for w in bearish if w in text)
    if bull > bear:
        return "ğŸŸ¢"
    elif bear > bull:
        return "ğŸ”´"
    return "âšª"

def extract_posts_from_json(raw_text: str) -> List[Dict]:
    """ä»åŸå§‹ JSON æ–‡æœ¬ä¸­æå–å¸–å­"""
    posts = []
    
    # æ‰¾åˆ°æ‰€æœ‰ "text":"..." çš„å†…å®¹
    # é›ªçƒçš„å†…å®¹åœ¨ "text":"<p>...</p>" æˆ– "text":"..." ä¸­
    text_pattern = r'"text":"(.*?)"(?:,"|})'
    texts = re.findall(text_pattern, raw_text, re.DOTALL)
    
    # æ‰¾åˆ°æ‰€æœ‰æ—¶é—´æˆ³
    time_pattern = r'"created_at":(\d+)'
    times = re.findall(time_pattern, raw_text)
    
    # æ‰¾åˆ°æ‰€æœ‰ä½œè€…
    author_pattern = r'"screen_name":"(.*?)"'
    authors = re.findall(author_pattern, raw_text)
    
    # ç»„åˆæ•°æ®ï¼ˆå–å‰20æ¡ï¼‰
    for i in range(min(len(texts), 20)):
        try:
            text = texts[i]
            # åè½¬ä¹‰
            text = text.replace('\\"', '"').replace('\\n', '\n').replace('\\\\', '\\').replace('<br/>', '\n')
            # å»é™¤ HTML æ ‡ç­¾
            text = re.sub(r'<[^>]+>', '', text)
            # å»é™¤è‚¡ç¥¨ä»£ç æ ‡è®°
            text = re.sub(r'\$.*?\$', '', text)
            text = text.strip()
            
            if len(text) < 5:
                continue
            
            ts = int(times[i]) if i < len(times) else 0
            author = authors[i] if i < len(authors) else "åŒ¿å"
            
            posts.append({
                'text': text,
                'author': author,
                'time': datetime.fromtimestamp(ts/1000).strftime('%m-%d %H:%M') if ts else "",
                'sentiment': analyze_sentiment(text),
            })
        except:
            continue
    
    return posts

def fetch_stock(symbol: str, name: str) -> List[Dict]:
    """æŠ“å–å•åªè‚¡ç¥¨"""
    print(f"\nğŸ“ˆ {name} ({symbol})")
    print("-" * 60)
    
    timestamp = int(time.time() * 1000)
    url = f"https://xueqiu.com/statuses/search.json?count=20&comment=0&symbol={symbol}&hl=0&source=user&sort=time&page=1&_={timestamp}"
    
    try:
        # æ‰“å¼€é¡µé¢
        r1 = subprocess.run(
            ['openclaw', 'browser', 'open', url],
            capture_output=True, text=True, timeout=30
        )
        
        match = re.search(r'id:\s*([A-F0-9]+)', r1.stdout)
        if not match:
            print("   âš ï¸ æ— æ³•æ‰“å¼€é¡µé¢")
            return []
        
        target_id = match.group(1)
        time.sleep(2)
        
        # è·å–å¿«ç…§
        r2 = subprocess.run(
            ['openclaw', 'browser', 'snapshot', '--target-id', target_id],
            capture_output=True, text=True, timeout=30
        )
        
        # å…³é—­é¡µé¢
        subprocess.run(
            ['openclaw', 'browser', 'close', '--target-id', target_id],
            capture_output=True, timeout=10
        )
        
        # æå–åŸå§‹ JSON å­—ç¬¦ä¸²
        line = r2.stdout.strip()
        
        # æ‰¾åˆ° "{ å¼€å§‹çš„éƒ¨åˆ†
        if ': "' not in line:
            print("   âš ï¸ æ ¼å¼é”™è¯¯")
            return []
        
        # æå– JSON éƒ¨åˆ†
        start = line.find('"{')
        end = line.rfind('}"')
        
        if start < 0 or end <= start:
            print("   âš ï¸ æœªæ‰¾åˆ°æ•°æ®")
            return []
        
        raw_json = line[start+1:end+1]
        
        # ç”¨æ­£åˆ™æå–å¸–å­
        posts = extract_posts_from_json(raw_json)
        
        # è¿‡æ»¤24å°æ—¶å†…çš„
        now_ts = datetime.now().timestamp() * 1000
        one_day_ms = 24 * 60 * 60 * 1000
        
        filtered = []
        for p in posts:
            # ä»æ—¶é—´å­—ç¬¦ä¸²è§£ææ—¶é—´æˆ³ï¼ˆç®€å•å¤„ç†ï¼‰
            filtered.append(p)
        
        print(f"   âœ… è·å– {len(filtered)} æ¡")
        return filtered
        
    except Exception as e:
        print(f"   âŒ é”™è¯¯: {str(e)[:50]}")
        return []

def main():
    print("=" * 60)
    print("ğŸ§ é›ªçƒèˆ†æƒ…ç›‘æ§ - V6 æ­£åˆ™ç‰ˆ")
    print(f"â° {datetime.now().strftime('%H:%M:%S')}")
    print("=" * 60)
    
    all_data = {}
    for symbol, name in SYMBOLS:
        posts = fetch_stock(symbol, name)
        all_data[symbol] = posts
        time.sleep(1)
    
    # ä¿å­˜
    import json
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    ts = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    json_file = os.path.join(OUTPUT_DIR, f'xueqiu_{ts}.json')
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump({'time': datetime.now().isoformat(), 'data': all_data}, f, ensure_ascii=False, indent=2)
    
    # æ‰“å°ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š èˆ†æƒ…æŠ¥å‘Š")
    print("=" * 60)
    
    for symbol, name in SYMBOLS:
        posts = all_data.get(symbol, [])
        bull = len([p for p in posts if p['sentiment'] == 'ğŸŸ¢'])
        bear = len([p for p in posts if p['sentiment'] == 'ğŸ”´'])
        
        print(f"\nğŸ“Œ {name} ({symbol})")
        print(f"   å…± {len(posts)} æ¡ | ğŸŸ¢{bull} ğŸ”´{bear}")
        
        for i, p in enumerate(posts[:3], 1):
            print(f"   {i}. {p['sentiment']} {p['text'][:45]}...")
    
    print(f"\nğŸ’¾ ä¿å­˜åˆ°: {json_file}")
    print("=" * 60)
    print("âœ… å®Œæˆ!")

if __name__ == "__main__":
    main()
